{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: termcolor in /Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages (1.1.0)\n",
      "\u001b[31mERROR: Error checking for conflicts.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3021, in _dep_map\n",
      "    return self.__dep_map\n",
      "  File \"/Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _DistInfoDistribution__dep_map\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3012, in _parsed_pkg_info\n",
      "    return self._pkg_info\n",
      "  File \"/Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2815, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _pkg_info\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/commands/install.py\", line 517, in _warn_about_conflicts\n",
      "    package_set, _dep_info = check_install_conflicts(to_install)\n",
      "  File \"/Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/operations/check.py\", line 114, in check_install_conflicts\n",
      "    package_set, _ = create_package_set_from_installed()\n",
      "  File \"/Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages/pip/_internal/operations/check.py\", line 53, in create_package_set_from_installed\n",
      "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
      "  File \"/Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 2736, in requires\n",
      "    dm = self._dep_map\n",
      "  File \"/Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3023, in _dep_map\n",
      "    self.__dep_map = self._compute_dependencies()\n",
      "  File \"/Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3032, in _compute_dependencies\n",
      "    for req in self._parsed_pkg_info.get_all('Requires-Dist') or []:\n",
      "  File \"/Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 3014, in _parsed_pkg_info\n",
      "    metadata = self.get_metadata(self.PKG_INFO)\n",
      "  File \"/Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1420, in get_metadata\n",
      "    value = self._get(path)\n",
      "  File \"/Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages/pip/_vendor/pkg_resources/__init__.py\", line 1616, in _get\n",
      "    with open(path, 'rb') as stream:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/pranavpomalapally/opt/anaconda3/lib/python3.7/site-packages/botocore-1.20.33.dist-info/METADATA'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy \n",
    "import warnings\n",
    "import sys\n",
    "!{sys.executable} -m pip install termcolor\n",
    "from termcolor import colored\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial import distance; \n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(students, employers):\n",
    "    df = pd.read_csv(students)\n",
    "    df['Problem Solving'] = df['Rank each skill on the list first to last. [Problem Solving]'].astype(str).str[0]\n",
    "    df['Creativity'] = df['Rank each skill on the list first to last. [Creativity]'].astype(str).str[0]\n",
    "    df['Research'] = df['Rank each skill on the list first to last. [Research]'].astype(str).str[0]\n",
    "    df['Time Management'] = df['Rank each skill on the list first to last. [Time Management]'].astype(str).str[0]\n",
    "    df['Communication'] = df['Rank each skill on the list first to last. [Communication]'].astype(str).str[0]\n",
    "    # df['Critical Thinking'] = df[' [Critical Thinking]'].astype(str).str[0]\n",
    "\n",
    "    newdf = df[['Problem Solving', 'Creativity', 'Research', 'Time Management', 'Communication']]\n",
    "    newdf['Problem Solving'].replace(\"n\", value=\"0\", inplace=True)\n",
    "    newdf['Creativity'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Research'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Time Management'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Communication'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    #print(newdf)\n",
    "\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    new_df = pd.DataFrame(scaler.fit_transform(newdf), columns=newdf.columns[:], index=newdf.index)\n",
    "\n",
    "    # print(new_df)\n",
    "    # Setting the amount of clusters to test out\n",
    "    cluster_cnt = [i for i in range(2, 12, 1)]\n",
    "\n",
    "    # Establishing empty lists to store the scores for the evaluation metrics\n",
    "    s_scores = []\n",
    "\n",
    "    db_scores = []\n",
    "\n",
    "    # Looping through different iterations for the number of clusters\n",
    "    for i in cluster_cnt:\n",
    "        \n",
    "        # Hierarchical Agglomerative Clustering with different number of clusters\n",
    "        hac = AgglomerativeClustering(n_clusters=i)\n",
    "        \n",
    "        hac.fit(new_df)\n",
    "        \n",
    "        cluster_assignments = hac.labels_\n",
    "        \n",
    "        ## KMeans Clustering with different number of clusters\n",
    "        k_means = KMeans(n_clusters=i)\n",
    "        \n",
    "        k_means.fit(new_df)\n",
    "        \n",
    "        cluster_assignments = k_means.predict(new_df)\n",
    "        \n",
    "        # Appending the scores to the empty lists    \n",
    "        s_scores.append(silhouette_score(new_df, cluster_assignments))\n",
    "        \n",
    "        db_scores.append(davies_bouldin_score(new_df, cluster_assignments))\n",
    "    return s_scores, db_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation(y, x=[i for i in range(2, 12, 1)]):\n",
    "    \"\"\"\n",
    "    Plots the scores of a set evaluation metric. Prints out the max and min values of the evaluation scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating a DataFrame for returning the max and min scores for each cluster\n",
    "    df = pd.DataFrame(columns=['Cluster Score'], index=[i for i in range(2, len(y)+2)])\n",
    "    df['Cluster Score'] = y\n",
    "    \n",
    "    # print('Max Value: Cluster #', df[df['Cluster Score']==df['Cluster Score'].max()])\n",
    "    # print('\\nMin Value: Cluster #', df[df['Cluster Score']==df['Cluster Score'].min()])\n",
    "    # print('\\n')\n",
    "    \n",
    "    # Plotting out the scores based on cluster count\n",
    "    # plt.figure(figsize=(16,6))\n",
    "    # plt.style.use('ggplot')\n",
    "    # plt.plot(x,y)\n",
    "    # plt.xlabel('# of Clusters')\n",
    "    # plt.ylabel('Score')\n",
    "    # plt.show()\n",
    "    return df['Cluster Score']==df['Cluster Score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_cluster(csv, num_clusters, etc=None):\n",
    "    df = pd.read_csv(csv)\n",
    "    # print(df['Rank each skill on the list first to last. [Problem Solving]'])\n",
    "    df['Problem Solving'] = df['Rank each skill on the list first to last. [Problem Solving]'].astype(str).str[0]\n",
    "    df['Creativity'] = df['Rank each skill on the list first to last. [Creativity]'].astype(str).str[0]\n",
    "    df['Research'] = df['Rank each skill on the list first to last. [Research]'].astype(str).str[0]\n",
    "    df['Time Management'] = df['Rank each skill on the list first to last. [Time Management]'].astype(str).str[0]\n",
    "    df['Communication'] = df['Rank each skill on the list first to last. [Communication]'].astype(str).str[0]\n",
    "    df['Critical Thinking'] = df['Rank each skill on the list first to last. [Critical Thinking ]'].astype(str).str[0]\n",
    "\n",
    "    newdf = df[['Problem Solving', 'Creativity', 'Research', 'Time Management', 'Communication', 'Critical Thinking']]\n",
    "    newdf['Problem Solving'].replace(\"n\", value=\"0\", inplace=True)\n",
    "    newdf['Creativity'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Research'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Time Management'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Communication'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Critical Thinking'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    # print(newdf)\n",
    "\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    # print(df)\n",
    "    new_df = pd.DataFrame(scaler.fit_transform(newdf), columns=newdf.columns[:], index=newdf.index)\n",
    "\n",
    "    # print(new_df)\n",
    "\n",
    "    clustering = AgglomerativeClustering(num_clusters)\n",
    "\n",
    "    # Fitting\n",
    "    clustering.fit(new_df)\n",
    "\n",
    "    # Getting cluster assignments\n",
    "    cluster_assignments = clustering.labels_\n",
    "\n",
    "    # Unscaling the categories then replacing the scaled values\n",
    "    if 'Best email to reach you' in df.columns:\n",
    "        df = df[['Best email to reach you', 'Select your major and minor (check all that apply)']].join(pd.DataFrame(scaler.inverse_transform(newdf), columns=newdf.columns[:], index=newdf.index))\n",
    "        #df = df[['Best email to reach you']].join(pd.DataFrame(scaler.inverse_transform(newdf), columns=newdf.columns[:], index=newdf.index))\n",
    "    else:\n",
    "        df = df[['Company Name', 'Majors and Minors (check all that apply)']].join(pd.DataFrame(scaler.inverse_transform(newdf), columns=newdf.columns[:], index=newdf.index))\n",
    "        #df = df[['Company Name']].join(pd.DataFrame(scaler.inverse_transform(newdf), columns=newdf.columns[:], index=newdf.index))\n",
    "    # Assigning the clusters to each profile\n",
    "    df['Cluster #'] = cluster_assignments\n",
    "\n",
    "    # Viewing the dating profiles with cluster assignments\n",
    "    # print(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(students, employers, num_clusters):\n",
    "    from clustering import cluster; import pandas as pd; import numpy as np; import scipy; from scipy.spatial import distance; from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "    clusteredEmployers = our_cluster(employers, num_clusters)\n",
    "    clusteredStudents = our_cluster(students, num_clusters)\n",
    "    \n",
    "    #change majors to lists\n",
    "    me = 'Majors and Minors (check all that apply)'\n",
    "    ms = 'Select your major and minor (check all that apply)'\n",
    "    clusteredEmployers[me] = clusteredEmployers[me].apply(lambda x: x.split(';'))\n",
    "    clusteredStudents[ms] = clusteredStudents[ms].fillna('NA')\n",
    "    clusteredStudents[ms] = clusteredStudents[ms].apply(lambda x: x.split(';'))\n",
    "    \n",
    "    for index, employer in clusteredEmployers.iterrows():\n",
    "        #filter by cluster\n",
    "        cluster = employer['Cluster #']\n",
    "        filtered_students = clusteredStudents[clusteredStudents['Cluster #'] == cluster]\n",
    "        \n",
    "        #filter by major\n",
    "        employer_majors = employer[me]\n",
    "        filtered_students_m = pd.DataFrame()\n",
    "        for s in employer_majors:\n",
    "            rows = filtered_students[filtered_students[ms].apply(lambda x: s in x)]\n",
    "            filtered_students_m = filtered_students_m.append(rows)\n",
    "        filtered_students = filtered_students_m\n",
    "    \n",
    "        \n",
    "        # top_students = []\n",
    "        best_student = \"\"\n",
    "        best_arr = []\n",
    "        most_similar = -1\n",
    "        scores = []\n",
    "        names = []\n",
    "        for index, student in filtered_students.iterrows():\n",
    "            arr = employer.values.tolist()\n",
    "            student_arr = student.values.tolist()\n",
    "            employer_values = np.array(arr[2:])\n",
    "            student_values = np.array(student_arr[2:])\n",
    "            cosine = cosine_similarity(employer_values.reshape(1, -1), student_values.reshape(1, -1))[0][0]\n",
    "            name = student_arr[0]\n",
    "            # print(name)\n",
    "            scores.append(cosine)\n",
    "            names.append(name)\n",
    "        # print(names)\n",
    "        top_students = sorted(zip(scores, names), reverse=True)[:3]\n",
    "        if top_students != []:\n",
    "            print((\"The best students for \" + employer['Company Name'] + \" are:\"))\n",
    "            for i in range(0, len(top_students)):\n",
    "                print(colored((str(i+1)+\". \" + str(top_students[i][1]) + \" with a \" + str(round(top_students[i][0] * 100, 1)) + \"% similarity.\"), \"green\")) \n",
    "            print()\n",
    "        else:\n",
    "            print(colored((\"No optimal students found for \" + employer['Company Name'] + \" based on given preferences. \\n\"), \"red\"))\n",
    "        # print(\"Student: \", best_arr)\n",
    "        # print(\"Employer: \", employer_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mSilhouette Score Optimization: \n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'clustering'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-723f9da67ce4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Silhouette Score Optimization: \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memployers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_score_num_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4849d72e672f>\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(students, employers, num_clusters)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memployers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mclustering\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mclusteredEmployers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mour_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memployers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclusteredStudents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mour_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'clustering'"
     ]
    }
   ],
   "source": [
    "# students = path + \"Student_Registration.csv\"\n",
    "# employers = path + \"CORRECT_Employer_Full_Registration.csv\"\n",
    "students = \"students.csv\"\n",
    "employers = \"employers.csv\"\n",
    "s_scores = optimize(students, employers)[0]\n",
    "db_scores = optimize(students, employers)[1]\n",
    "s_score_num_clusters = plot_evaluation(s_scores)\n",
    "for i in range(2, len(s_score_num_clusters)):\n",
    "    if s_score_num_clusters[i]:\n",
    "        s_score_num_clusters = i\n",
    "        break\n",
    "db_score_num_clusters = plot_evaluation(db_scores)\n",
    "for i in range(2, len(db_score_num_clusters)):\n",
    "    if db_score_num_clusters[i]:\n",
    "        db_score_num_clusters = i\n",
    "        break\n",
    "# print(\"\\n \\n\")\n",
    "\n",
    "# print(\"Silhoutte Score Optimal Clusters: \", s_score_num_clusters, \"\\n\")\n",
    "\n",
    "print(colored((\"Silhouette Score Optimization: \\n\"), \"blue\"))\n",
    "match(students, employers, s_score_num_clusters)\n",
    "print(\"\\n \\n\")\n",
    "\n",
    "# print(\"Davies-Bouldin Score Optimal Clusters: \", db_score_num_clusters, \"\\n\")\n",
    "print(colored((\"Davies-Bouldin Score Optimization: \\n\"), \"blue\"))\n",
    "match(students, employers, db_score_num_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = pd.read_csv('Student_Registration.csv')\n",
    "print(students.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

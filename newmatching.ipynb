{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd038ab967b2267d68b0202dcdb65cc8c8f426ec1bd4d22c16b71b32e84eff9dc94",
   "display_name": "Python 3.9.2 64-bit ('.venv')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy \n",
    "import warnings\n",
    "from termcolor import colored\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial import distance; \n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(students, employers):\n",
    "    students = pd.read_csv(students)\n",
    "    employers = pd.read_csv(employers)\n",
    "\n",
    "    curr = employers.rename(columns={'Company Name': 'Name', 'Majors and Minors (check all that apply)':'Majors/Minors'})\n",
    "    students = students.rename(collumns={'Best email to reach you':'Name', 'Select your major and minor (check all that apply)':'Majors/Minors'})\n",
    "\n",
    "    for i in range(len(employers.index)):\n",
    "\n",
    "        # obtain i-th employer from dataframe\n",
    "        curr = employers.iloc[[i]]\n",
    "\n",
    "        # perform filtering on all students based on criteria of i-th employer\n",
    "        filtered = round1_filter(students, curr)\n",
    "\n",
    "        # create dataframe with filtered students and i-th employer\n",
    "        appended = filtered.append(curr)\n",
    "\n",
    "        # find optimal number of clusters for appended dataframe\n",
    "        s_score, db_score = optimize_skills(filtered, curr)\n",
    "        s_clusters = find_num_clusters(plot_evaluation(s_score))\n",
    "        db_clusters = find_num_clusters(plot_evaluation(db_score))\n",
    "\n",
    "        # perform clustering on appended using both of the optimized cluster scores\n",
    "        # use appended dataframe because we need apply a bonus weight if student and employer's clusters match\n",
    "        s_clustered = round2_cluster(appended, s_clusters)\n",
    "        db_clustered = round2_cluster(appened, db_clusters)\n",
    "\n",
    "        # get list of top 10-12 candidates as a list of tuples (x, y) where x is the candidate's email address and y is their similarity score\n",
    "        s_optimal_matchings = match_skills(s_clustered)\n",
    "        db_optimal_matchings = match_skills(db_clustered)\n",
    "\n",
    "        # cleanup all dataframes and get new dataframe which includes candidate's email, similarity score, and social causes columns\n",
    "        s_cleaned_up = cleanup(s_clustered, s_optimal_matchings)\n",
    "        db_cleaned_up = cleanup(db_clustered, db_optimal_matchings)\n",
    "\n",
    "        # find optimal number of clusters for social causes\n",
    "        s_social_score, db_social_score = optimize_social(s_cleaned_up)\n",
    "        s_social_clusters = find_num_clusters(plot_evaluation(s_social_score))\n",
    "        db_social_clusters = find_num_clusters(plot_evaluation(db_social_score))\n",
    "\n",
    "        # find optimal clusterings for social causes\n",
    "        s_social = round3_socialcluster(appended, s_social_clusters)\n",
    "        db_social = round3_socialcluster(appended, db_social_clusters)\n",
    "\n",
    "        # return list of top 3-5 candidates based on social clustering\n",
    "        s_final = match_social(s_social)\n",
    "        db_final = match_socials(db_social)\n",
    "\n",
    "        # pretty print top candidates for current employer\n",
    "        pretty_print(s_final)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round1_filter(students, employer):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_skills(appended):\n",
    "    df = appended\n",
    "    df['Problem Solving'] = df['Rank each skill on the list first to last. [Problem Solving]'].astype(str).str[0]\n",
    "    df['Creativity'] = df['Rank each skill on the list first to last. [Creativity]'].astype(str).str[0]\n",
    "    df['Research'] = df['Rank each skill on the list first to last. [Research]'].astype(str).str[0]\n",
    "    df['Time Management'] = df['Rank each skill on the list first to last. [Time Management]'].astype(str).str[0]\n",
    "    df['Communication'] = df['Rank each skill on the list first to last. [Communication]'].astype(str).str[0]\n",
    "    # df['Critical Thinking'] = df[' [Critical Thinking]'].astype(str).str[0]\n",
    "\n",
    "    newdf = df[['Problem Solving', 'Creativity', 'Research', 'Time Management', 'Communication']]\n",
    "    newdf['Problem Solving'].replace(\"n\", value=\"0\", inplace=True)\n",
    "    newdf['Creativity'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Research'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Time Management'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Communication'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    #print(newdf)\n",
    "\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    new_df = pd.DataFrame(scaler.fit_transform(newdf), columns=newdf.columns[:], index=newdf.index)\n",
    "\n",
    "    # print(new_df)\n",
    "    # Setting the amount of clusters to test out\n",
    "    cluster_cnt = [i for i in range(2, 12, 1)]\n",
    "\n",
    "    # Establishing empty lists to store the scores for the evaluation metrics\n",
    "    s_scores = []\n",
    "\n",
    "    db_scores = []\n",
    "\n",
    "    # Looping through different iterations for the number of clusters\n",
    "    for i in cluster_cnt:\n",
    "        \n",
    "        # Hierarchical Agglomerative Clustering with different number of clusters\n",
    "        hac = AgglomerativeClustering(n_clusters=i)\n",
    "        \n",
    "        hac.fit(new_df)\n",
    "        \n",
    "        cluster_assignments = hac.labels_\n",
    "        \n",
    "        ## KMeans Clustering with different number of clusters\n",
    "        k_means = KMeans(n_clusters=i)\n",
    "        \n",
    "        k_means.fit(new_df)\n",
    "        \n",
    "        cluster_assignments = k_means.predict(new_df)\n",
    "        \n",
    "        # Appending the scores to the empty lists    \n",
    "        s_scores.append(silhouette_score(new_df, cluster_assignments))\n",
    "        \n",
    "        db_scores.append(davies_bouldin_score(new_df, cluster_assignments))\n",
    "    return s_scores, db_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation(scores):\n",
    "    df = pd.DataFrame(columns=['Cluster Score'], index=[i for i in range(2, len(y)+2)])\n",
    "    df['Cluster Score'] = y\n",
    "    \n",
    "    # print('Max Value: Cluster #', df[df['Cluster Score']==df['Cluster Score'].max()])\n",
    "    # print('\\nMin Value: Cluster #', df[df['Cluster Score']==df['Cluster Score'].min()])\n",
    "    # print('\\n')\n",
    "    \n",
    "    # Plotting out the scores based on cluster count\n",
    "    # plt.figure(figsize=(16,6))\n",
    "    # plt.style.use('ggplot')\n",
    "    # plt.plot(x,y)\n",
    "    # plt.xlabel('# of Clusters')\n",
    "    # plt.ylabel('Score')\n",
    "    # plt.show()\n",
    "    return df['Cluster Score']==df['Cluster Score'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_num_clusters(scores)\n",
    "for i in range(2, len(score)):\n",
    "    if scores[i]:\n",
    "        scores = i\n",
    "        return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round2_cluster(appended, num_clusters):\n",
    "    df = appended\n",
    "    df['Problem Solving'] = df['Rank each skill on the list first to last. [Problem Solving]'].astype(str).str[0]\n",
    "    df['Creativity'] = df['Rank each skill on the list first to last. [Creativity]'].astype(str).str[0]\n",
    "    df['Research'] = df['Rank each skill on the list first to last. [Research]'].astype(str).str[0]\n",
    "    df['Time Management'] = df['Rank each skill on the list first to last. [Time Management]'].astype(str).str[0]\n",
    "    df['Communication'] = df['Rank each skill on the list first to last. [Communication]'].astype(str).str[0]\n",
    "    df['Critical Thinking'] = df['Rank each skill on the list first to last. [Critical Thinking ]'].astype(str).str[0]\n",
    "\n",
    "    newdf = df[['Problem Solving', 'Creativity', 'Research', 'Time Management', 'Communication', 'Critical Thinking']]\n",
    "    newdf['Problem Solving'].replace(\"n\", value=\"0\", inplace=True)\n",
    "    newdf['Creativity'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Research'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Time Management'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Communication'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    newdf['Critical Thinking'].replace(\"n\", value=\"0\", inplace=True) \n",
    "    # print(newdf)\n",
    "\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    # print(df)\n",
    "    new_df = pd.DataFrame(scaler.fit_transform(newdf), columns=newdf.columns[:], index=newdf.index)\n",
    "\n",
    "    # print(new_df)\n",
    "\n",
    "    clustering = AgglomerativeClustering(num_clusters)\n",
    "\n",
    "    # Fitting\n",
    "    clustering.fit(new_df)\n",
    "\n",
    "    # Getting cluster assignments\n",
    "    cluster_assignments = clustering.labels_\n",
    "\n",
    "    # Unscaling the categories then replacing the scaled values\n",
    "    df = df[['Name']].join(pd.DataFrame(scaler.inverse_transform(newdf), columns=newdf.columns[:], index=newdf.index))\n",
    "    \n",
    "    # Assigning the clusters to each profile\n",
    "    df['Cluster #'] = cluster_assignments\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_skills(clustered):\n",
    "    employer = clustered.iloc[[-1]]\n",
    "    filtered_students = clustered.iloc[[0:-1]]\n",
    "    best_student = \"\"\n",
    "    best_arr = []\n",
    "    most_similar = -1\n",
    "    scores = []\n",
    "    names = []\n",
    "    for index, student in filtered_students.iterrows():\n",
    "        arr = employer.values.tolist()\n",
    "        student_arr = student.values.tolist()\n",
    "        employer_values = np.array(arr[2:])\n",
    "        student_values = np.array(student_arr[2:])\n",
    "        cosine = cosine_similarity(employer_values.reshape(1, -1), student_values.reshape(1, -1))[0][0]\n",
    "        name = student_arr[0]\n",
    "        # print(name)\n",
    "        scores.append(cosine)\n",
    "        names.append(name)\n",
    "    top_students = sorted(zip(scores, names), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(clustered, matchings):\n",
    "    # add column for scores"
   ]
  }
 ]
}